# Post-MVP Capture & UX Enhancements

## Task: Camera Capture with AI Vision Analysis
Add camera/webcam capture to Quick Dump modal. When image captured, send to AI model (like Claude) with ability to see the image AND read accompanying text context. AI should:
- Extract text from image
- Cross-reference with similar images online to identify diagrams/charts
- Use question/answer text context to understand what the image represents
- Feed into both learning pipeline and concept extraction
Research needed: Best approach for multimodal AI integration, image similarity search APIs, cost implications of vision API calls.

## Task: Unified Capture Pathway UX Audit
Current UI doesn't clearly teach users the three capture pathways:
1. Quick Dump → Inbox (for later processing)
2. Main Page → Extract Concepts (immediate AI extraction)
3. Learning Pipeline (structured card creation)

Need to:
- Audit current UX for clarity
- Design visual cues/onboarding that silently guide users
- Consider whether pathways should be consolidated or kept separate
- User test with medical residents to validate understanding
Research needed: UX patterns for multi-pathway apps, progressive disclosure, silent onboarding techniques.

## Task: AI Image Context Understanding
Enhance AI service to handle images with rich context:
- Accept image + text together (multimodal input)
- Use surrounding text to disambiguate image content
- Identify medical diagrams, charts, algorithms from images
- Generate appropriate card formats based on image type (e.g., labeled diagram → multiple cloze cards)
Research needed: Claude vision API capabilities, prompt engineering for medical image understanding, cost optimization strategies.
